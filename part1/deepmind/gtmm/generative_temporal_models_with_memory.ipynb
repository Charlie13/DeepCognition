{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GENERATIVE TEMPORAL MODELS WITH MEMORY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 싸이그래머 : DeepCognition : 파트 1 [1]\n",
    "* 김무성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Contents\n",
    "* ABSTRACT\n",
    "* 1 INTRODUCTION\n",
    "* 2 GENERATIVE TEMPORAL MODELS\n",
    "    - 2.1 VARIATIONAL INFERENCE FOR GTMS\n",
    "* 3 GENERATIVE TEMPORAL MODELS WITH EXTERNAL MEMORY\n",
    "    - 3.1 INTROSPECTIVE-GTMMS\n",
    "    - 3.2 MODELS WITH CONTENT-BASED ADDRESSING\n",
    "* 4 EVALUATION METHODOLOGY\n",
    "    - 4.1 TRAINING DETAILS\n",
    "* 5 EXPERIMENTAL RESULTS\n",
    "    - 5.1 PERFECT RECALL\n",
    "    - 5.2 PARITY RECALL\n",
    "    - 5.3 ONE-SHOT RECALL\n",
    "    - 5.4 LEARNING DYNAMIC DEPENDENCIES\n",
    "    - 5.5 SIMILARITY-CUED RECALL\n",
    "    - 5.6 NAVIGATION IN AN MNIST MAP\n",
    "    - 5.7 TOWARDS COHERENT GENERATION IN REALISTIC 3D ENVIRONMENTS\n",
    "* 6 DISCUSSION AND CONCLUSIONS\n",
    "* A PER STEP VARIATIONAL LOWER BOUND\n",
    "* B VISUAL ARCHITECTURES\n",
    "    - B.1 TASKS WITH DIGITS AND CHARACTERS\n",
    "    - B.2 TASKS INVOLVING FRAMES OF 3D ENVIRONMENTS\n",
    "* C GENERATED SAMPLES FOR SELECT TASKS\n",
    "* D PSEUDOCODE FOR GENERATING ARTIFICIAL SEQUENCES WITH CHARACTERS AND DIGITS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 참고자료\n",
    "* [2] Generative Model 101 - https://www.facebook.com/SKTBrain/photos/a.302919646745523.1073741828.293034461067375/313724185665069/?type=3&theater\n",
    "* [3] (PRML) Variational Inference - http://norman3.github.io/prml/docs/chapter10/1\n",
    "* [4] Variational Inference: Foundations and Modern Methods - https://media.nips.cc/Conferences/2016/Slides/6199-Slides.pdf\n",
    "* [5] [DL輪読会] Hybrid computing using a neural network with dynamic external memory - http://www.slideshare.net/YuusukeIwasawa/dl-hybrid-computing-using-a-neural-network-with-dynamic-external-memory\n",
    "영어번역) https://github.com/psygrammer/remind/blob/master/part1/deepmind/SMA_NN/dliwasawadnc-161220014044.pptx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ABSTRACT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We consider the general problem of <font color=\"red\">modeling temporal data with long-range dependencies</font>, wherein new observations are fully or partially predictable based on temporally-distant, past observations.\n",
    "* we introduce <font color=\"red\">Generative Temporal Models augmented with external memory systems</font>.\n",
    "    - They are developed within the variational inference framework, which pro- vides both a practical training methodology and methods to gain insight into the models’ operation.\n",
    "*  We show, on a range of problems with sparse, long-term temporal dependencies, that these models store information from early in a sequence, and reuse this stored information efficiently.\n",
    "    - This allows them to perform substantially <font color=\"red\">better than existing models based on well-known recurrent neural networks, like LSTMs</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 INTRODUCTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Generative Temporal Models (GTMs)\n",
    "    - Many GTMs—whether they are linear or nonlinear, deterministic or stochastic—assume that the underlying temporal dynamics is governed by low-order Markov transitions and use fixed-dimensional sufficient statistics.\n",
    "        - Hidden Markov Models\n",
    "        - Kalman filters\n",
    "    - Most recently proposed GTMs, \n",
    "        - variational recurrent neural networks (VRNNs)  \n",
    "        - Deep Kalman Filters (Krishnan et al., 2015), \n",
    "            - are built upon well-known recurrent neural networks, like Long Short-Term Memory (LSTM) \n",
    "            - In principle, these recurrent networks can solve variable-order Markovian problems, as the additive dynamics are designed to store and protect information over long intervals.\n",
    "* GTMM\n",
    "    - We demonstrate that generative temporal models with memory (GTMMs) \n",
    "        - exhibit a significantly enhanced capacity to solve tasks involving complex, long-term temporal dependencies.\n",
    "    - a new positional memory architecture referred to as \n",
    "        - an Introspection Network, \n",
    "        - the Neural Turing Machine (NTM) (Graves et al., 2014), \n",
    "        - the Least-Recently Used access mechanism (LRU) (Santoro et al., 2016), and \n",
    "        - the Differentiable Neural Computer (DNC) (Graves et al., 2016).\n",
    "* variational inference\n",
    "    - We show that variational inference makes it easy to train scalable models capable of handling high-dimensional input streams leading to new state-of-the-art temporal VAEs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 GENERATIVE TEMPORAL MODELS\n",
    "* 2.1 VARIATIONAL INFERENCE FOR GTMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap2.png\" width=800 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap1.png\" width=800 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Distributions\n",
    "* Conditional dependencies\n",
    "    - transition map\n",
    "    - prior map\n",
    "    - observation map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap_cd.jpg\" width=800 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 VARIATIONAL INFERENCE FOR GTMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap3.png\" width=800 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap4.png\" width=800 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 GENERATIVE TEMPORAL MODELS WITH EXTERNAL MEMORY\n",
    "* 3.1 INTROSPECTIVE-GTMMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap5.png\" width=800 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.png\" width=800 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 INTROSPECTIVE-GTMMS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The memory M is a first-in-first-out buffer with at most L storage locations into which latent variables zt are written as they are generated at each time step. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Controller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The controller is responsible for memory retrieval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap7.png\" width=800 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gating mechanism"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap8.png\" width=800 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap6.png\" width=800 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 MODELS WITH CONTENT-BASED ADDRESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We now develop GTMMs with three alternative types of memory architectures:\n",
    "    - NTM-GTMM\n",
    "        - Neural Turing Machine\n",
    "            - content-based addressing\n",
    "            - positional addressing\n",
    "    - LRU-GTMM\n",
    "        - Least-Recently Used (LRU) access, which exclusively employs content-based addressing\n",
    "    - DNC-GTMM\n",
    "        - Differentiable Neural Computer (DNC)\n",
    "            - which uses \n",
    "                - content-based addressing and \n",
    "                - a mechanism of positional addressing that links positions \n",
    "                    - in memory based on temporal adjacency of writing. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Memory. \n",
    "Unlike the first-in-first-out buffer used previously, the memory for NTMs and DNCs are a generic storage that allows information to be written to, and read from any location.\n",
    "\n",
    "#### Controller. \n",
    "The controller uses an LSTM network frnn (Eq. 13) that updates the state-history ht and the external memory Mt using the latent variables from the previous time step and any additional, context information ct on which the generative model is conditioned:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap9.png\" width=800 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap10.png\" width=800 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 EVALUATION METHODOLOGY\n",
    "* 4.1 TRAINING DETAILS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap13.png\" width=400 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 TRAINING DETAILS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap12.png\" width=800 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 EXPERIMENTAL RESULTS\n",
    "* 5.1 PERFECT RECALL\n",
    "* 5.2 PARITY RECALL\n",
    "* 5.3 ONE-SHOT RECALL\n",
    "* 5.4 LEARNING DYNAMIC DEPENDENCIES\n",
    "* 5.5 SIMILARITY-CUED RECALL\n",
    "* 5.6 NAVIGATION IN AN MNIST MAP\n",
    "* 5.7 TOWARDS COHERENT GENERATION IN REALISTIC 3D ENVIRONMENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1 PERFECT RECALL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap14.png\" width=800 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap15.png\" width=800 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 PARITY RECALL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap16.png\" width=800 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap17.png\" width=800 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3 ONE-SHOT RECALL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap18.png\" width=800 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap19.png\" width=800 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4 LEARNING DYNAMIC DEPENDENCIES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap20.png\" width=800 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap21.png\" width=800 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.5 SIMILARITY-CUED RECALL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap22.png\" width=800 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap23.png\" width=800 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.6 NAVIGATION IN AN MNIST MAP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap24.png\" width=800 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap25.png\" width=800 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap26.png\" width=800 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.7 TOWARDS COHERENT GENERATION IN REALISTIC 3D ENVIRONMENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap27.png\" width=800 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap28.png\" width=800 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap42.png\" width=800 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6 DISCUSSION AND CONCLUSIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A PER STEP VARIATIONAL LOWER BOUND"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap29.png\" width=800 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap30.png\" width=800 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap31.png\" width=800 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B VISUAL ARCHITECTURES\n",
    "* B.1 TASKS WITH DIGITS AND CHARACTERS\n",
    "* B.2 TASKS INVOLVING FRAMES OF 3D ENVIRONMENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B.1 TASKS WITH DIGITS AND CHARACTERS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap32.png\" width=800 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B.2 TASKS INVOLVING FRAMES OF 3D ENVIRONMENTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C GENERATED SAMPLES FOR SELECT TASKS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap33.png\" width=800 />\n",
    "<img src=\"figures/cap34.png\" width=800 />\n",
    "<img src=\"figures/cap35.png\" width=800 />\n",
    "<img src=\"figures/cap36.png\" width=800 />\n",
    "<img src=\"figures/cap37.png\" width=800 />\n",
    "<img src=\"figures/cap38.png\" width=800 />\n",
    "<img src=\"figures/cap39.png\" width=800 />\n",
    "<img src=\"figures/cap40.png\" width=800 />\n",
    "<img src=\"figures/cap41.png\" width=800 />\n",
    "<img src=\"figures/cap42.png\" width=800 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D PSEUDOCODE FOR GENERATING ARTIFICIAL SEQUENCES WITH CHARACTERS AND DIGITS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"figures/cap43.png\" width=800 />\n",
    "<img src=\"figures/cap44.png\" width=800 />\n",
    "<img src=\"figures/cap45.png\" width=800 />\n",
    "<img src=\"figures/cap46.png\" width=800 />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 참고자료"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [1] Generative Temporal Models with Memory - https://arxiv.org/abs/1702.04649\n",
    "* [2] Generative Model 101 - https://www.facebook.com/SKTBrain/photos/a.302919646745523.1073741828.293034461067375/313724185665069/?type=3&theater\n",
    "* [3] (PRML) Variational Inference - http://norman3.github.io/prml/docs/chapter10/1\n",
    "* [4] Variational Inference: Foundations and Modern Methods - https://media.nips.cc/Conferences/2016/Slides/6199-Slides.pdf\n",
    "* [5] [DL輪読会] Hybrid computing using a neural network with dynamic external memory - http://www.slideshare.net/YuusukeIwasawa/dl-hybrid-computing-using-a-neural-network-with-dynamic-external-memory\n",
    "    - 영어번역) https://github.com/psygrammer/remind/blob/master/part1/deepmind/SMA_NN/dliwasawadnc-161220014044.pptx\n",
    "* [6] Recent Progress in Gernerative Modeling - http://scaledml.org/2016/slides/ilya.pdf\n",
    "    - 현재 발표자료 비공개. 행사 끝나고 공개한다고 함."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
